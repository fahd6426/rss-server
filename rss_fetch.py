import os
import requests
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import random

API_KEY = os.getenv("BLOGGER_API_KEY")
BLOG_ID = os.getenv("BLOG_ID")

URL = "https://www.yallakora.com"

def load_posted_titles():
    try:
        with open("posted_titles.txt", "r", encoding="utf-8") as f:
            return set(line.strip() for line in f)
    except FileNotFoundError:
        return set()

def fetch_articles():
    # Ø¨Ø¹Ø¶ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ù…Ø§ ØªØ¹Ø·ÙŠÙƒ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¥Ù„Ø§ Ù„Ùˆ Ø¬Øª Ù…Ù† Ù…ØªØµÙØ­
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
    }
    try:
        response = requests.get(URL, headers=headers, timeout=15)
        response.raise_for_status()
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø©: {e}")
        return []

    soup = BeautifulSoup(response.text, "html.parser")

    articles = []
    # Ù‡Ù†Ø§ Ø§Ù†Øª ÙƒÙ†Øª Ø­Ø§Ø· class Ø§Ø³Ù…Ù‡ news-blockØŒ Ù„Ùˆ Ø§Ù„Ù…ÙˆÙ‚Ø¹ ØºÙŠØ± Ø´ÙƒÙ„Ù‡ Ù…Ø§ Ø±Ø§Ø­ ÙŠØ±Ø¬Ø¹ Ø´ÙŠ
    news_items = soup.find_all("div", class_="news-block")

    print(f"â„¹ï¸ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù„ÙŠ Ù„Ù‚ÙŠØªÙ‡Ø§ ÙÙŠ Ø§Ù„ØµÙØ­Ø©: {len(news_items)}")

    for item in news_items:
        title_tag = item.find("h2")
        img_tag = item.find("img")
        summary_tag = item.find("p")
        category_tag = item.find("span", class_="category")

        if title_tag and img_tag and summary_tag:
            article = {
                "title": title_tag.get_text(strip=True),
                "image": img_tag.get("src"),
                "content": summary_tag.get_text(strip=True),
                "category": category_tag.get_text(strip=True) if category_tag else "Ø±ÙŠØ§Ø¶Ø©",
            }
            articles.append(article)

    return articles

def rephrase_content(content):
    intros = [
        "Ù†Ù‚Ø¯Ù… Ù„ÙƒÙ… Ø£Ø¨Ø±Ø² Ø§Ù„Ø£Ø­Ø¯Ø§Ø«: ",
        "ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙŠÙˆÙ… Ø¹Ù† Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ØªØ§Ù„ÙŠ: ",
        "ÙÙŠ Ù…ØªØ§Ø¨Ø¹Ø© Ù„Ø£Ù‡Ù… Ø§Ù„Ø£Ø®Ø¨Ø§Ø±: "
    ]
    conclusions = [
        "ØªØ§Ø¨Ø¹ÙˆÙ†Ø§ Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙŠÙˆÙ…ÙŠØ©.",
        "Ù‡Ø°Ø§ ÙƒØ§Ù† Ù…Ù„Ø®Øµ Ø§Ù„Ø®Ø¨Ø±ØŒ Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ ØªØ§Ø¨Ø¹ÙˆØ§ Ù…ÙˆÙ‚Ø¹Ù†Ø§.",
        "Ù†Ø³ØªÙ…Ø± Ø¨ØªØºØ·ÙŠØ© ÙƒÙ„ Ø¬Ø¯ÙŠØ¯ ÙÙŠ Ø¹Ø§Ù„Ù… Ø§Ù„Ø±ÙŠØ§Ø¶Ø©."
    ]
    intro = random.choice(intros)
    conclusion = random.choice(conclusions)
    return f"{intro}{content} {conclusion}"

def post_to_blogger(article, posted_titles):
    if article["title"] in posted_titles:
        print(f'â­ ØªØ®Ø·ÙŠ Ù…ÙƒØ±Ø±: {article["title"]}')
        return

    try:
        service = build('blogger', 'v3', developerKey=API_KEY)

        content = f'''
        <img src="{article["image"]}" style="max-width:100%;">
        <h2>{article["title"]}</h2>
        <p>{rephrase_content(article["content"])}</p>
        <p>ØªØµÙ†ÙŠÙ: {article["category"]}</p>
        <p>Ø§Ù„Ù…ØµØ¯Ø±: YallaKora</p>
        '''

        post_body = {
            "kind": "blogger#post",
            "title": article["title"],
            "content": content
        }

        post = service.posts().insert(blogId=BLOG_ID, body=post_body, isDraft=False).execute()
        print(f'âœ… ØªÙ… Ù†Ø´Ø± Ø§Ù„Ø®Ø¨Ø±: {post["title"]}')

        posted_titles.add(article["title"])
        with open("posted_titles.txt", "a", encoding="utf-8") as f:
            f.write(article["title"] + "\n")

    except HttpError as e:
        print(f'âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ Blogger: {e}')

def main():
    print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø³ÙƒØ±Ø¨Øª Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±...")
    posted_titles = load_posted_titles()
    articles = fetch_articles()

    if not articles:
        print("âŒ Ù…Ø§ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù€ selector Ø£Ùˆ Ù…Ù† Ø£Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ø§ ÙŠØ­Ø¬Ø¨ Ø§Ù„Ø¨ÙˆØª.")
        return

    for article in articles:
        post_to_blogger(article, posted_titles)

    print("âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø³ÙƒØ±Ø¨Øª.")

if __name__ == "__main__":
    main()
