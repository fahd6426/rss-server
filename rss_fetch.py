import os
import requests
from bs4 import BeautifulSoup
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import random

# =========================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† GitHub Secrets
# =========================
API_KEY = os.getenv("BLOGGER_API_KEY")
BLOG_ID = os.getenv("BLOG_ID")

# Ø±Ø§Ø¨Ø· Ø§Ù„Ù€ RSS Ù…Ù† ÙŠÙ„Ø§ ÙƒÙˆØ±Ø©
RSS_URL = "https://www.yallakora.com/rss/latest-posts"


# =========================================
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ù„ÙŠ Ù†Ø´Ø±Ù†Ø§Ù‡Ø§ Ù‚Ø¨Ù„ (Ø¹Ø´Ø§Ù† Ù…Ø§ Ù†ÙƒØ±Ø±)
# =========================================
def load_posted_titles():
    try:
        with open("posted_titles.txt", "r", encoding="utf-8") as f:
            return set(line.strip() for line in f)
    except FileNotFoundError:
        return set()


# =========================================
# Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† RSS
# =========================================
def fetch_articles():
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Ø®Ù„Ø§ØµØ© RSS ...")
    try:
        resp = requests.get(RSS_URL, timeout=15)
        resp.raise_for_status()
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø®Ù„Ø§ØµØ©: {e}")
        return []

    # Ù†Ù‚Ø±Ø£ Ø§Ù„Ù€ XML
    soup = BeautifulSoup(resp.content, "xml")
    items = soup.find_all("item")
    print(f"ğŸ“¡ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø®Ù„Ø§ØµØ©: {len(items)}")

    articles = []
    for item in items:
        title = item.title.get_text(strip=True) if item.title else None
        description = item.description.get_text(strip=True) if item.description else ""
        # Ù†Ø­Ø§ÙˆÙ„ Ù†Ø¬ÙŠØ¨ ØµÙˆØ±Ø© Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯Ø©
        image_url = ""
        enclosure = item.find("enclosure")
        if enclosure and enclosure.get("url"):
            image_url = enclosure.get("url")

        if title:
            articles.append({
                "title": title,
                "content": description,
                "image": image_url,
                "category": "Ø±ÙŠØ§Ø¶Ø©"
            })

    return articles


# =========================================
# Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ© Ø¨Ø³ÙŠØ·Ø©
# =========================================
def rephrase_content(content):
    intros = [
        "Ù†Ù‚Ø¯Ù… Ù„ÙƒÙ… Ø£Ø¨Ø±Ø² Ù…Ø§ Ø¬Ø§Ø¡ ÙÙŠ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„ØªØ§Ù„ÙŠ: ",
        "ÙÙŠ Ù…ØªØ§Ø¨Ø¹Ø© Ù„Ø£Ù‡Ù… Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ÙƒØ±Ø©: ",
        "ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø¨Ø± Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ Ø§Ù„ØªØ§Ù„ÙŠ: "
    ]
    endings = [
        "ØªØ§Ø¨Ø¹ÙˆÙ†Ø§ Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªØºØ·ÙŠØ§Øª Ø§Ù„ÙŠÙˆÙ…ÙŠØ©.",
        "Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø²ÙˆØ±ÙˆØ§ Ø§Ù„Ù…Ø¯ÙˆÙ†Ø©.",
        "Ù†ÙˆØ§ÙÙŠÙƒÙ… Ø¨ÙƒÙ„ Ø¬Ø¯ÙŠØ¯ Ø£ÙˆÙ„Ø§Ù‹ Ø¨Ø£ÙˆÙ„."
    ]
    intro = random.choice(intros)
    ending = random.choice(endings)
    return f"{intro}{content} {ending}"


# =========================================
# Ù†Ø´Ø± Ø§Ù„Ø®Ø¨Ø± Ø¹Ù„Ù‰ Blogger
# =========================================
def post_to_blogger(article, posted_titles):
    # Ù„Ùˆ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ù…ÙƒØ±Ø± Ù„Ø§ ØªÙ†Ø´Ø±Ù‡
    if article["title"] in posted_titles:
        print(f'â­ ØªÙ… ØªØ®Ø·ÙŠ Ø®Ø¨Ø± Ù…ÙƒØ±Ø±: {article["title"]}')
        return

    try:
        service = build("blogger", "v3", developerKey=API_KEY)

        # Ù†Ø¨Ù†ÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        html_parts = []

        if article["image"]:
            html_parts.append(f'<img src="{article["image"]}" style="max-width:100%;">')

        html_parts.append(f'<h2>{article["title"]}</h2>')
        html_parts.append(f'<p>{rephrase_content(article["content"])}</p>')
        html_parts.append(f'<p>Ø§Ù„ØªØµÙ†ÙŠÙ: {article["category"]}</p>')
        html_parts.append('<p>Ø§Ù„Ù…ØµØ¯Ø±: ÙŠÙ„Ø§ ÙƒÙˆØ±Ø©</p>')

        content_html = "\n".join(html_parts)

        post_body = {
            "kind": "blogger#post",
            "title": article["title"],
            "content": content_html,
        }

        post = service.posts().insert(
            blogId=BLOG_ID,
            body=post_body,
            isDraft=False  # Ù„Ùˆ ØªØ¨ÙŠÙ‡Ø§ Ù…Ø³ÙˆØ¯Ø© Ø®Ù„Ù‡ True
        ).execute()

        print(f'âœ… ØªÙ… Ù†Ø´Ø± Ø§Ù„Ø®Ø¨Ø±: {post["title"]}')

        # Ù†Ø­ÙØ¸ Ø§Ù„Ø¹Ù†ÙˆØ§Ù† ÙÙŠ Ø§Ù„Ù…Ù„Ù
        posted_titles.add(article["title"])
        with open("posted_titles.txt", "a", encoding="utf-8") as f:
            f.write(article["title"] + "\n")

    except HttpError as e:
        # Ù‡Ù†Ø§ ØºØ§Ù„Ø¨Ø§Ù‹ Ù„Ùˆ Ø·Ù„Ø¹ 403 ÙŠÙƒÙˆÙ† Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ§Øª Blogger Ø£Ùˆ Ø¥Ù† Ø§Ù„Ù€ API key Ù…Ø§ ÙŠÙƒÙÙŠ
        print(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ Blogger: {e}")


# =========================================
# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# =========================================
def main():
    print("ğŸŸ£ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª...")
    posted_titles = load_posted_titles()
    articles = fetch_articles()

    if not articles:
        print("âŒ Ù…Ø§ ÙÙŠÙ‡ Ø£Ø®Ø¨Ø§Ø± Ù†Ø³ØªÙˆØ±Ø¯Ù‡Ø§ Ù…Ù† Ø§Ù„Ù€ RSS. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø£Ùˆ Ø¬Ø±Ø¨ Ù…ØµØ¯Ø± Ø«Ø§Ù†ÙŠ.")
        return

    for article in articles[:5]:  # Ù†Ù†Ø´Ø± Ø£ÙˆÙ„ 5 Ø¨Ø³ Ø¹Ø´Ø§Ù† Ù…Ø§ ÙŠØ·ÙØ­
        post_to_blogger(article, posted_titles)

    print("âœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø³ÙƒØ±Ø¨Øª.")


if __name__ == "__main__":
    main()
